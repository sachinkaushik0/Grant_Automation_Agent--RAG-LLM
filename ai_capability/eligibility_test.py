import json
import os
import re
from collections import defaultdict
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
import requests

# Path to JSON
file_path = "grants.json"

# Ollama setup
OLLAMA_API = "http://localhost:11434/api/chat"
HEADERS = {"Content-Type": "application/json"}
MODEL = "llama3"

# Global data stores
program_chunks = defaultdict(list)
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Load grants and chunk by program_id
def load_and_chunk():
    
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        content = f.read() 

    clean_content = re.sub(r"[\x00-\x1F\x7F]", "", content)
    grants_data = json.loads(clean_content)

    print(f" Total Grants in JSON: {len(grants_data)}")
    documents = []
    for grant in grants_data:
        grant_text = "\n".join([f"{k}: {v}" for k, v in grant.items()])
        doc = Document(page_content=grant_text, metadata={"program_id": grant.get('program_id', 'unknown')})
        documents.append(doc)

    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    chunks = splitter.split_documents(documents)

    for chunk in chunks:
        pid = chunk.metadata['program_id']
        program_chunks[pid].append(chunk)

    print(f" Loaded {len(program_chunks)} programs with {len(chunks)} chunks.")

# Call Ollama to generate eligibility questions
def generate_questions_from_llm(content, grant_type="COMPANY"):
    prompt = f"""
        You are a grant eligibility expert. Based on the grant information provided, extract the key eligibility requirements 
        that an ORGANIZATION must meet to qualify for this grant.
        
        Focus on extracting concrete eligibility criteria such as:
        - Company size/employee requirements
        - Revenue thresholds or limitations
        - Years in operation
        - Industry or sector requirements
        - Legal structure requirements (for-profit, non-profit, etc.)
        - Location or jurisdiction requirements
        - Previous funding history limitations
        - Any other specific eligibility criteria mentioned
        
        Format your response as a bulleted list of eligibility points. Each point should be clear and concise.
        If the grant information doesn't specify a particular criterion, don't include it.

        Grant Information
        ------------------
        {content}
        ------------------

        Key eligibility requirements for organizations:
        """
    payload = {
        "model": MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "stream": False
    }

    try:
        response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)
        data = response.json()

        # Print full response for debugging (optional)
        if 'message' not in data:
            print(" Full LLM response:", json.dumps(data, indent=2))

        return data['message']['content'] if 'message' in data else " LLM response format unexpected"

    except Exception as e:
        return f" LLM error: {e}"


# Local answer logic (no LLM)
def extract_raw_eligibility(text):
    lines = text.splitlines()
    bullets = []
    for line in lines:
        if re.search(r'\b(must|should|required|eligible|only|need to|have to)\b', line, re.IGNORECASE):
            bullets.append("- " + line.strip())
    return bullets if bullets else ["No clear eligibility rules found."]

# Main loop
def main():
    load_and_chunk()

    while True:
        user_input = input("\nEnter a program_id to test eligibility (or type 'exit'): ")
        if user_input.lower() == 'exit':
            break

        try:
            pid = int(user_input)
            chunks = program_chunks.get(pid, [])
            if not chunks:
                print(" No data found for that program_id.")
                continue

            combined_text = "\n".join(chunk.page_content for chunk in chunks)

            print("\n Eligibility Questions (Generated by LLM):")
            questions = generate_questions_from_llm(combined_text)
            print(questions)

            

        except ValueError:
            print(" Please enter a valid numeric program_id.")

if __name__ == "__main__":
    main()
